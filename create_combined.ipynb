{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/ns1254/mimicgen/envs/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import imageio\n",
    "import tqdm\n",
    "from robomimic.utils.file_utils import create_hdf5_filter_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create new file taking demo from multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_files_groups ={\n",
    "    \"/home/ns1254/data_franka/bellpepper_oma/ola_114.hdf5\": [\"good\"], \n",
    "    \"/home/ns1254/data_franka/bellpepper_oma/marzan_73.hdf5\": [\"good\"],\n",
    "    \"/home/ns1254/data_franka/bellpepper_oma/akash_100.hdf5\": [\"good\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath: /home/ns1254/data_franka/bellpepper_oma/ola_114.hdf5 groups: ['good'] #demo: 94\n",
      "filepath: /home/ns1254/data_franka/bellpepper_oma/marzan_73.hdf5 groups: ['good'] #demo: 51\n",
      "filepath: /home/ns1254/data_franka/bellpepper_oma/akash_100.hdf5 groups: ['good'] #demo: 35\n"
     ]
    }
   ],
   "source": [
    "for filepath, groups in hdf5_files_groups.items():\n",
    "    f = h5py.File(filepath, \"r\")\n",
    "    if len(groups)<1:\n",
    "        demos = list(f[\"data\"].keys())      \n",
    "    elif len(groups)==1:\n",
    "        demos = [b.decode('utf-8') for b in f[\"mask\"][groups[0]]]\n",
    "    else:\n",
    "        print('---------not implemented-------------')\n",
    "    \n",
    "    print(f\"filepath: {filepath} groups: {groups} #demo: {len(demos)}\")\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_group(src_group, dest_group):\n",
    "    # Copy attributes\n",
    "    for attr_name, attr_value in src_group.attrs.items():\n",
    "        dest_group.attrs[attr_name] = attr_value\n",
    "\n",
    "    for key, item in src_group.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            # Create a new group in the destination and recursively copy contents\n",
    "            new_group = dest_group.create_group(key)\n",
    "            copy_group(item, new_group)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            # Copy datasets\n",
    "            dataset = dest_group.create_dataset(key, data=item[...])\n",
    "            # Copy attributes for the dataset\n",
    "            for attr_name, attr_value in item.attrs.items():\n",
    "                dataset.attrs[attr_name] = attr_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_demos(f_src, f_dest, demos2copy, next_id):\n",
    "    new_demo_names=[]\n",
    "    i=next_id\n",
    "    for demo_name in tqdm.tqdm(demos2copy):\n",
    "        demo=f_src['data'][demo_name]  \n",
    "\n",
    "        demo_name_new=\"demo_\"+str(i) \n",
    "        new_demo=f_dest[\"data\"].create_group(demo_name_new) \n",
    "        copy_group(demo, new_demo) \n",
    "\n",
    "        new_demo_names.append(demo_name_new)\n",
    "        i = i+1\n",
    "\n",
    "    return i , new_demo_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/mask\" (0 members)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file_path = \"/home/ns1254/data_franka/bellpepper_oma/combined_oma_good.hdf5\"\n",
    "\n",
    "fc = h5py.File(new_file_path, \"w\")\n",
    "fc.create_group(\"data\")\n",
    "fc.create_group(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath: /home/ns1254/data_franka/bellpepper_oma/ola_114.hdf5 groups: ['good'] #demo: 94\n",
      "First: copying attributes from the first file.\n",
      "copying demos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:06<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating filter key: ola_114 with 94 demos\n",
      "\n",
      "filepath: /home/ns1254/data_franka/bellpepper_oma/marzan_73.hdf5 groups: ['good'] #demo: 51\n",
      "copying demos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:06<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating filter key: marzan_73 with 51 demos\n",
      "\n",
      "filepath: /home/ns1254/data_franka/bellpepper_oma/akash_100.hdf5 groups: ['good'] #demo: 35\n",
      "copying demos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:02<00:00, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating filter key: akash_100 with 35 demos\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "next_id = 0\n",
    "for filepath, groups in hdf5_files_groups.items():\n",
    "    f_src = h5py.File(filepath, \"r\")\n",
    "    if len(groups)<1:\n",
    "        demos2copy = list(f_src[\"data\"].keys())      \n",
    "    elif len(groups)==1:\n",
    "        demos2copy = [b.decode('utf-8') for b in f_src[\"mask\"][groups[0]]]\n",
    "    else:\n",
    "        print('---------not implemented-------------')\n",
    "        print('ignored-------------')\n",
    "        continue\n",
    "    \n",
    "    print(f\"filepath: {filepath} groups: {groups} #demo: {len(demos2copy)}\")\n",
    "\n",
    "    #copy attributes from first file\n",
    "    if next_id==0:\n",
    "        print('First: copying attributes from the first file.')\n",
    "        for attr_name, attr_value in f_src.attrs.items():\n",
    "            fc.attrs[attr_name] = attr_value\n",
    "\n",
    "    print('copying demos...')\n",
    "    next_id , new_demo_names=copy_demos(f_src, fc, demos2copy, next_id)\n",
    "\n",
    "    src_filename=os.path.basename(filepath).split(\".\")[0]\n",
    "    \n",
    "    print(f\"creating filter key: {src_filename} with {len(new_demo_names)} demos\")\n",
    "    demos= np.array(new_demo_names, dtype='S8')   \n",
    "    filter_keys=sorted([elem for elem in demos]) \n",
    "    filter_lengths = create_hdf5_filter_key(hdf5_path=new_file_path, demo_keys=filter_keys, key_name=src_filename)\n",
    "\n",
    "    print('')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akash_100 (35,)\n",
      "marzan_73 (51,)\n",
      "ola_114 (94,)\n"
     ]
    }
   ],
   "source": [
    "for key in fc['mask'].keys():\n",
    "    print(key, fc['mask'][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos =  list(fc[\"data\"].keys())     \n",
    "len(demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
